{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dec6fd17",
   "metadata": {},
   "source": [
    "# PS4-3 PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcd6583",
   "metadata": {},
   "source": [
    "From the definition of vector projection we obtain\n",
    "\n",
    "\\begin{align*}\n",
    "||f_u(x)||_2^2=f_u(x)^Tf_u(x)=x^Tu\n",
    "\\end{align*}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{align*}\n",
    "(x^{(i)})^Tf_u(x^{(i)}) = (f_u(x^{(i)}))^Tx^{(i)}=||f_u(x^{(i)})||_2^2\n",
    "\\end{align*}\n",
    "\n",
    "Then,\n",
    "\n",
    "\\begin{align*}\n",
    "&\\arg\\min_{u:||u||=1}\\sum_{i=1}^m||x^{(i)}-f_u(x)||_2^2\\\\\n",
    "=&\\arg\\min_{u:||u||=1}\\sum_{i=1}^m\\left(x^{(i)}-f_u(x^{(i)})\\right)^T\\left(x^{(i)}-f_u(x^{(i)})\\right)\\\\\n",
    "=&\\arg\\min_{u:||u||=1}\\sum_{i=1}^m\\left[(x^{(i)})^Tx^{(i)}-(x^{(i)})^Tf_u(x^{(i)})-(f_u(x^{(i)}))^Tx^{(i)}+(f_u(x^{(i)}))^Tf_u(x^{(i)})\\right]\\\\\n",
    "=&\\arg\\min_{u:||u||=1}\\sum_{i=1}^m-||f_u(x^{(i)})||_2^2\\\\\n",
    "=&\\arg\\max_{u:||u||=1}\\frac{1}{m}\\sum_{i=1}^m ((x^{(i)})^Tu)^2\\\\\n",
    "=&\\arg\\max_{u:||u||=1}\\frac{1}{m}\\sum_{i=1}^m u^Tx^{(i)}(x^{(i)})^Tu\\\\\n",
    "=&\\arg\\max_{u:||u||=1}u^T\\left(\\frac{1}{m}\\sum_{i=1}^m x^{(i)}(x^{(i)})^T\\right)u\\\\\n",
    "=&\\arg\\max_{u:||u||=1}u^T\\Sigma u,\n",
    "\\end{align*}\n",
    "\n",
    "where $\\Sigma$ is covariance matrix of data. By applying Langrange multiplier we can prove that $u$ is a principle eigenvector of $\\Sigma$ and thus the minimization process gives the first principal component of the data."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
