{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38d8045c",
   "metadata": {},
   "source": [
    "# PS4-2 Off Policy Evaluation and Causal Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e71cf5",
   "metadata": {},
   "source": [
    "### (a) Importance Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5497f9b7",
   "metadata": {},
   "source": [
    "When $\\hat\\pi_0 = \\pi_0$, the importance sampling estimator has the form:\n",
    "\n",
    "\\begin{align*}\n",
    "&\\mathbb E_{\\substack{s\\sim p(s)\\\\ a\\sim\\pi_0(s,a)}}\\frac{\\pi_1(s,a)}{\\pi_0(s,a)}R(s,a)\\\\\n",
    "=&\\sum_{(s,a)}\\frac{\\pi_1(s,a)}{\\pi_0(s,a)}R(s,a)p(s,a)\\\\\n",
    "=&\\sum_{(s,a)}\\frac{\\pi_1(s,a)}{\\pi_0(s,a)}R(s,a)p(s)\\pi_0(s,a)\\\\\n",
    "=&\\sum_{(s,a)}\\pi_1(s,a)R(s,a)p(s)\\\\\n",
    "=&\\mathbb E_{\\substack{s\\sim p(s)\\\\ a\\sim\\pi_1(s,a)}}R(s,a).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201bfeed",
   "metadata": {},
   "source": [
    "### (b) Weighted Importance Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bbb1e0",
   "metadata": {},
   "source": [
    "When $\\hat\\pi_0 = \\pi_0$, the weighted importance sampling estimator has the form:\n",
    "\n",
    "\\begin{align*}\n",
    "&\\frac{\\mathbb E_{\\substack{s\\sim p(s)\\\\a\\sim\\pi_0(s,a)}}\\frac{\\pi_1(s,a)}{\\pi_0(s,a)}R(s,a)}{\\mathbb E_{\\substack{s\\sim p(s)\\\\a\\sim\\pi_0(s,a)}}\\frac{\\pi_1(s,a)}{\\pi_0(s,a)}}\\\\\n",
    "=&\\frac{\\mathbb E_{\\substack{s\\sim p(s)\\\\ a\\sim\\pi_1(s,a)}}R(s,a)}{\\sum_{(s,a)}p(s)\\pi_0(s,a)\\frac{\\pi_1(s,a)}{\\pi_0(s,a)}}\\\\\n",
    "=&\\frac{\\mathbb E_{\\substack{s\\sim p(s)\\\\ a\\sim\\pi_1(s,a)}}R(s,a)}{1}\\\\\n",
    "=&\\mathbb E_{\\substack{s\\sim p(s)\\\\ a\\sim\\pi_1(s,a)}}R(s,a).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdd1b18",
   "metadata": {},
   "source": [
    "### (c) Bias of the Weighted Importance Sampling Estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e255324c",
   "metadata": {},
   "source": [
    "Consider the case where there is only one state $s$ and only on action $a$ (we can assume the latter because many policies are deterministic). Then the weighted importance sampling estimator becomes\n",
    "\n",
    "\\begin{align*}\n",
    "&\\frac{\\mathbb E_{\\substack{s\\sim p(s)\\\\a\\sim\\pi_0(s,a)}}\\frac{\\pi_1(s,a)}{\\hat\\pi_0(s,a)}R(s,a)}{\\mathbb E_{\\substack{s\\sim p(s)\\\\a\\sim\\pi_0(s,a)}}\\frac{\\pi_1(s,a)}{\\hat\\pi_0(s,a)}}\\\\\n",
    "=&\\frac{\\sum_{(s,a)}\\frac{\\pi_1(s,a)}{\\hat\\pi_0(s,a)}R(s,a)p(s)\\pi_0(s,a)}{\\sum_{(s,a)}\\frac{\\pi_1(s,a)}{\\hat\\pi_0(s,a)}p(s)\\pi_0(s,a)}\\\\\n",
    "=&\\frac{\\frac{\\pi_1(s,a)}{\\hat\\pi_0(s,a)}R(s,a)p(s)\\pi_0(s,a)}{\\frac{\\pi_1(s,a)}{\\hat\\pi_0(s,a)}p(s)\\pi_0(s,a)}\\\\\n",
    "=&R(s,a).\n",
    "\\end{align*}\n",
    "\n",
    "Note that $s, a$ in the above expression is sampled from $p(s)$ and $\\pi_0(s,a)$. However, we want the estimator to estimate the expected reward when $s, a$ are sampled from $p(s)$ and $\\pi_1(s,a)$. Therefore, the weighted importance sampling estimator is biased when $\\pi_1 \\neq \\pi_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b246bd2e",
   "metadata": {},
   "source": [
    "### (d) Doubly Robust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8478017",
   "metadata": {},
   "source": [
    "i. When $\\pi_1=\\pi_0$, the doubly robust estimator has the form:\n",
    "\n",
    "\\begin{align*}\n",
    "&\\sum_{(s,a)}p(s)\\pi_0(s,a)\\left[\\left(\\mathbb E_{a\\sim\\pi_1(s,a)}\\hat R(s,a)\\right)+\\frac{\\pi_1(s,a)}{\\pi_0(s,a)}\\left(R(s,a) - \\hat R(s,a)\\right)\\right]\\\\\n",
    "=&\\sum_{(s,a)}p(s)\\pi_0(s,a)\\left(\\sum_a\\pi_1(s,a)\\hat R(s,a)\\right)+\\sum_{(s,a)}p(s)\\pi_1(s,a)R(s,a)-\\sum_{(s,a)}p(s)\\pi_1(s,a)\\hat R(s,a).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0fa705",
   "metadata": {},
   "source": [
    "Note that the second term is \n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb E_{\\substack{s\\sim p(s)\\\\ a\\sim\\pi_1(s,a)}}R(s,a)\n",
    "\\end{align*}\n",
    "\n",
    "and the third term is\n",
    "\n",
    "\\begin{align*}\n",
    "-\\mathbb E_{\\substack{s\\sim p(s)\\\\ a\\sim\\pi_1(s,a)}}\\hat R(s,a).\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a372633",
   "metadata": {},
   "source": [
    "The first term can be simplified as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "&\\sum_{(s,a)}p(s)\\pi_0(s,a)\\left(\\sum_a\\pi_1(s,a)\\hat R(s,a)\\right)\\\\\n",
    "=&\\sum_s\\sum_a p(s)\\pi_0(s,a)\\left(\\sum_a\\pi_1(s,a)\\hat R(s,a)\\right)\\\\\n",
    "=&\\sum_s\\sum_a\\pi_0(s,a)\\left(\\sum_a p(s)\\pi_1(s,a)\\hat R(s,a)\\right).\n",
    "\\end{align*}\n",
    "\n",
    "Note that $\\sum_a\\pi_0(s,a)=1$, so the first term becomes\n",
    "\n",
    "\\begin{align*}\n",
    "\\sum_s\\sum_a p(s)\\pi_1(s,a)\\hat R(s,a) = \\mathbb E_{\\substack{s\\sim p(s)\\\\ a\\sim\\pi_1(s,a)}}\\hat R(s,a)\n",
    "\\end{align*}\n",
    "\n",
    "and cancels with the third term. Therefore, the doubly robust estimator is equal to $\\mathbb E_{\\substack{s\\sim p(s)\\\\ a\\sim\\pi_1(s,a)}}R(s,a)$ when $\\pi_1=\\pi_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23bf526",
   "metadata": {},
   "source": [
    "ii. From i we know that when $R(s,a) = \\hat R(s,a)$, the doubly robust estimator becomes\n",
    "\n",
    "\\begin{align*}\n",
    "&\\sum_{(s,a)}p(s)\\pi_0(s,a)\\mathbb E_{a\\sim\\pi_1(s,a)}\\hat R(s,a)\n",
    "\\end{align*}\n",
    "\n",
    "and is equal to $\\mathbb E_{\\substack{s\\sim p(s)\\\\ a\\sim\\pi_1(s,a)}} \\hat R(s,a) = \\mathbb E_{\\substack{s\\sim p(s)\\\\ a\\sim\\pi_1(s,a)}} R(s,a)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285b963c",
   "metadata": {},
   "source": [
    "### (e) Choose between importance sampling estimator and regression estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a0e20c",
   "metadata": {},
   "source": [
    "i. Choose importance sampling estimator. Since the drugs are randomly assigned to patients, $\\pi_0$ tends to be a uniform distribution and thus is easy to estimate, while the complicated interactions make it hard to fit the reward $R(s,a)$.\n",
    "\n",
    "ii. Choose regression estimator. Since $\\pi_0$ is very complicated and hard to estimate, while the reward $R(s,a)$ is easy to estimate."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
