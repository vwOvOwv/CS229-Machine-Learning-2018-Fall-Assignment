{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c2e0ef",
   "metadata": {},
   "source": [
    "# PS4-4 ICA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd1f184",
   "metadata": {},
   "source": [
    "### (a) Gaussian source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a865fe",
   "metadata": {},
   "source": [
    "When the source is drawn from standard Gaussian distribution, from notes we know\n",
    "\n",
    "\\begin{equation}\\notag\n",
    "l(W) = \\sum_{i=1}^n\\left(\\log|W|+\\sum_{j=1}^d\\log\\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{\\left(w_j^Tx^{(i)}\\right)^2}{2}\\right)\\right).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b15a6",
   "metadata": {},
   "source": [
    "Then perform standard MLE.\n",
    "\n",
    "\\begin{align*}\n",
    "\\nabla_Wl(W)&=n\\left(W^{-1}\\right)^T-\\frac{1}{2}\\sum_{i=1}^n\\nabla_W\\sum_{j=1}^d\\left(w_j^Tx^{(i)}\\right)^2\\\\\n",
    "&=n\\left(W^{-1}\\right)^T-\\frac{1}{2}\\sum_{i=1}^n2Wx^{(i)}\\left(x^{(i)}\\right)^T\\\\\n",
    "&=n\\left(W^{-1}\\right)^T-W\\sum_{i=1}^nx^{(i)}\\left(x^{(i)}\\right)^T\\\\\n",
    "&=n\\left(W^{-1}\\right)^T-WX^TX\n",
    "\\end{align*}\n",
    "\n",
    "Let $\\nabla_Wl(W_0)=0$, we obtain\n",
    "\n",
    "\\begin{align*}\n",
    "W_0^TW_0=n(X^TX)^{-1}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a87779",
   "metadata": {},
   "source": [
    "The ambiguity in computing $W$ is that there are multiple $W$'s satisfying the condition above, as long as \n",
    "\n",
    "$$W=OW_0,$$\n",
    "\n",
    "where $O$ is an orthogonal matrix and thus $W^TW=W_0^TW_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bb2a37",
   "metadata": {},
   "source": [
    "### (b) Laplace source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549a6b17",
   "metadata": {},
   "source": [
    "When the source is drawn from standard Laplace distribution, the log-likelihood function for a single sample $x^{(i)}$ becomes\n",
    "\\begin{align*}\n",
    "l(W) = \\log|W|+\\sum_{j=1}^d\\log\\frac{1}{2}\\exp\\left(-|w_j^Tx^{(i)}|\\right).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925ce50d",
   "metadata": {},
   "source": [
    "Then compute the gradient.\n",
    "\n",
    "\\begin{align*}\n",
    "\\nabla_Wl(W)&=\\left(W^{-1}\\right)^T-\\nabla_W\\sum_{j=1}^d|w_j^Tx^{(i)}|\\\\\n",
    "&=\\left(W^{-1}\\right)^T-\\mathrm{sign}\\left(Wx^{(i)}\\right)\\left(x^{(i)}\\right)^T\\\\\n",
    "\\end{align*}\n",
    "\n",
    "And the SGA update rule is\n",
    "\n",
    "$$W:=W+\\alpha\\left(\\left(W^{-1}\\right)^T-\\mathrm{sign}\\left(Wx^{(i)}\\right)\\left(x^{(i)}\\right)^T\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e78096b",
   "metadata": {},
   "source": [
    "### (c) Implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3de520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def update_W(W, x, learning_rate):\n",
    "    \"\"\"\n",
    "    Perform a gradient ascent update on W using data element x and the provided learning rate.\n",
    "\n",
    "    This function should return the updated W.\n",
    "\n",
    "    Use the laplace distribiution in this problem.\n",
    "\n",
    "    Args:\n",
    "        W: The W matrix for ICA\n",
    "        x: A single data element\n",
    "        learning_rate: The learning rate to use\n",
    "\n",
    "    Returns:\n",
    "        The updated W\n",
    "    \"\"\"\n",
    "    \n",
    "    # *** START CODE HERE ***\n",
    "    updated_W = W + learning_rate * (np.linalg.inv(W).T - np.outer(np.sign(W @ x), x.T))\n",
    "    # *** END CODE HERE ***\n",
    "\n",
    "    return updated_W\n",
    "\n",
    "\n",
    "def unmix(X, W):\n",
    "    \"\"\"\n",
    "    Unmix an X matrix according to W using ICA.\n",
    "\n",
    "    Args:\n",
    "        X: The data matrix\n",
    "        W: The W for ICA\n",
    "\n",
    "    Returns:\n",
    "        A numpy array S containing the split data\n",
    "    \"\"\"\n",
    "\n",
    "    S = np.zeros(X.shape)\n",
    "\n",
    "\n",
    "    # *** START CODE HERE ***\n",
    "    S = X @ W.T\n",
    "    # *** END CODE HERE ***\n",
    "\n",
    "    return S\n",
    "\n",
    "\n",
    "Fs = 11025\n",
    "\n",
    "def normalize(dat):\n",
    "    return 0.99 * dat / np.max(np.abs(dat))\n",
    "\n",
    "def load_data():\n",
    "    mix = np.loadtxt('./data/mix.dat')\n",
    "    return mix\n",
    "\n",
    "def save_W(W):\n",
    "    np.savetxt('output/W.txt',W)\n",
    "\n",
    "def save_sound(audio, name):\n",
    "    scipy.io.wavfile.write('output/{}.wav'.format(name), Fs, audio)\n",
    "\n",
    "def unmixer(X):\n",
    "    M, N = X.shape\n",
    "    W = np.eye(N)\n",
    "\n",
    "    anneal = [0.1 , 0.1, 0.1, 0.05, 0.05, 0.05, 0.02, 0.02, 0.01 , 0.01, 0.005, 0.005, 0.002, 0.002, 0.001, 0.001]\n",
    "    print('Separating tracks ...')\n",
    "    for lr in anneal:\n",
    "        print(lr)\n",
    "        rand = np.random.permutation(range(M))\n",
    "        for i in rand:\n",
    "            x = X[i]\n",
    "            W = update_W(W, x, lr)\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b1a1efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53442, 5)\n",
      "Separating tracks ...\n",
      "0.1\n",
      "0.1\n",
      "0.1\n",
      "0.05\n",
      "0.05\n",
      "0.05\n",
      "0.02\n",
      "0.02\n",
      "0.01\n",
      "0.01\n",
      "0.005\n",
      "0.005\n",
      "0.002\n",
      "0.002\n",
      "0.001\n",
      "0.001\n",
      "[[ 52.83337868  16.79535173  19.94059268 -10.1982649  -20.8969462 ]\n",
      " [ -9.93333916  -0.97878167  -4.67969942   8.0443386    1.78975024]\n",
      " [  8.31132067  -7.47665691  19.31501843  15.17431965 -14.32607253]\n",
      " [-14.66728796 -26.64498039   2.44086049  21.38241345  -8.42100435]\n",
      " [ -0.26910696  18.37442886   9.31246685   9.10279432  30.59440916]]\n"
     ]
    }
   ],
   "source": [
    "# Seed the randomness of the simulation so this outputs the same thing each time\n",
    "np.random.seed(0)\n",
    "X = normalize(load_data())\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "for i in range(X.shape[1]):\n",
    "    save_sound(X[:, i], 'mixed_{}'.format(i))\n",
    "\n",
    "W = unmixer(X)\n",
    "print(W)\n",
    "save_W(W)\n",
    "S = normalize(unmix(X, W))\n",
    "assert S.shape[1] == 5\n",
    "for i in range(S.shape[1]):\n",
    "    if os.path.exists('split_{}'.format(i)):\n",
    "        os.unlink('split_{}'.format(i))\n",
    "    save_sound(S[:, i], 'split_{}'.format(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ann_snn_ei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
