{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0e9c8dd",
   "metadata": {},
   "source": [
    "# PS3-4 Semi-supervised EM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65229460",
   "metadata": {},
   "source": [
    "### Derivation of Semi-supervised E-step and M-step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f812543f",
   "metadata": {},
   "source": [
    "First, plugin probability distribution $Q_i(z^{(i)})$ into the objective $l_{\\text{semi-sup}}(\\theta)$:\n",
    "\n",
    "\\begin{align*}\n",
    "l_{\\text{semi-sup}}(\\theta)&=\\sum_{i=1}^m\\log\\sum_{z^{(i)}}p(x^{(i)},z^{(i)};\\theta)+\\alpha l_{\\text{sup}}(\\theta)\\\\\n",
    "&=\\sum_{i=1}^m\\log\\sum_{z^{(i)}}Q_{i}(z^{(i)})\\left[\\frac{p(x^{(i)},z^{(i)};\\theta)}{Q_{i}(z^{(i)})}\\right]+\\alpha l_{\\text{sup}}(\\theta)\\\\\n",
    "&=\\sum_{i=1}^m\\log\\mathbb E_{z^{(i)}\\sim Q_i}\\left[\\frac{p(x^{(i)},z^{(i)};\\theta)}{Q_{i}(z^{(i)})}\\right]+\\alpha l_{\\text{sup}}(\\theta).\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Since $\\log x$ is concave, from Jensen's inequality we have\n",
    "\n",
    "\\begin{align*}\n",
    "l_{\\text{semi-sup}}(\\theta)&\\ge\\sum_{i=1}^m\\mathbb E_{z^{(i)}\\sim Q_i}\\left[\\log\\frac{p(x^{(i)},z^{(i)};\\theta)}{Q_{i}(z^{(i)})}\\right]+\\alpha l_{\\text{sup}}(\\theta).\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Note that $Q_i$ can be any distribution and we want $\\log\\mathbb E_{z^{(i)}\\sim Q_i}\\left[\\frac{p(x^{(i)},z^{(i)};\\theta)}{Q_{i}(z^{(i)})}\\right]=\\mathbb E_{z^{(i)}\\sim Q_i}\\left[\\log\\frac{p(x^{(i)},z^{(i)};\\theta)}{Q_{i}(z^{(i)})}\\right]$. \n",
    "\n",
    "From Jensen's inequality we know it's true if and only if $\\frac{p(x^{(i)},z^{(i)};\\theta)}{Q_{i}(z^{(i)})}$ is a constant. Therefore, we can set\n",
    "\n",
    "\\begin{align*}\n",
    "Q_i(z^{(i)})&:=\\frac{p(x^{(i)},z^{(i)};\\theta)}{\\sum_{z^{(i)}}p(x^{(i)},z^{(i)};\\theta)}\\\\\n",
    "&=\\frac{p(x^{(i)},z^{(i)};\\theta)}{p(x^{(i)};\\theta)}\\\\\n",
    "&=p(z^{(i)}|x^{(i)};\\theta).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a3ebe5",
   "metadata": {},
   "source": [
    "Therefore, for each iteration $t$ we set\n",
    "\n",
    "$$Q_i^{(t)}(z^{(i)})=p(z^{(i)}|x^{(i)};\\theta^{(t)})$$\n",
    "\n",
    "in E-step. In M-step we update $\\theta$ by setting\n",
    "\n",
    "$$\\theta^{(t+1)}=\\arg\\max_\\theta\\left[\\sum_{i=1}^m\\mathbb E_{z^{(i)}\\sim Q_i}\\left[\\log\\frac{p(x^{(i)},z^{(i)};\\theta)}{Q_{i}(z^{(i)})}\\right]+\\alpha\\left(\\sum_{i=1}^{\\tilde m}\\log p(\\tilde x^{(i)},\\tilde z^{(i)};\\theta)\\right)\\right].$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac0c959",
   "metadata": {},
   "source": [
    "### (a) Convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a748a28c",
   "metadata": {},
   "source": [
    "By setting $Q_i^{(t)}(z^{(i)})=p(z^{(i)}|x^{(i)};\\theta^{(t)})$ in E-step,\n",
    "\n",
    "$$l_{\\text{semi-sup}}(\\theta^{(t)})=\\sum_{i=1}^m\\mathbb E_{z^{(i)}\\sim Q_i}\\left[\\log\\frac{p(x^{(i)},z^{(i)};\\theta^{(t)})}{Q_{i}(z^{(i)})}\\right]+\\alpha l_{\\text{sup}}(\\theta^{(t)}),$$\n",
    "\n",
    "and in M-step we maximize $l_{\\text{semi-sup}}(\\theta^{(t)})$ and get $\\theta^{(t+1)}$, i.e.,\n",
    "\n",
    "$$\\theta^{(t+1)}=\\arg\\max_{\\theta^{(t)}} l_{\\text{semi-sup}}(\\theta^{(t)}).$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$l_{\\text{semi-sup}}(\\theta^{(t+1)})\\ge l_{\\text{semi-sup}}(\\theta^{(t)})$$\n",
    "\n",
    "and the algorithm will converge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b31fda",
   "metadata": {},
   "source": [
    "### (b) Semi-supervised E-step of GMM. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cc1362",
   "metadata": {},
   "source": [
    "The latent variable to be re-estimated is $z^{(i)}$. From derivation above we set\n",
    "\n",
    "\\begin{align*}\n",
    "w^{(i)}_j&:=Q_i(z^{(i)}=j)\\\\\n",
    "&=p(z^{(i)}=j|x^{(i)};\\theta)\\\\\n",
    "&=\\frac{p(x^{(i)}|z^{(i)}=j;\\mu_j,\\Sigma_j)p(z^{(i)}=j;\\phi)}{\\sum_{r=1}^kp(x^{(i)}|z^{(i)}=r;\\mu_r,\\Sigma_r)p(z^{(i)}=r;\\phi)},\n",
    "\\end{align*}\n",
    "\n",
    "where $i\\in\\{1,2,\\dots,m\\},j\\in\\{1,2,\\dots,k\\}$.\n",
    "\n",
    "From assumption we have\n",
    "\n",
    "\\begin{align*}\n",
    "&p(x^{(i)}|z^{(i)}=r;\\mu_r,\\Sigma_r)=\\frac{1}{\\left(2\\pi\\right)^{\\frac{n}{2}}|\\Sigma_r|^{\\frac{1}{2}}}\\exp\\left[-\\frac{1}{2}(x^{(i)}-\\mu_r)^T\\Sigma_r^{-1}(x^{(i)}-\\mu_r)\\right]\\\\\n",
    "&p(z^{(i)}=r;\\phi) = \\phi_r.\n",
    "\\end{align*}\n",
    "\n",
    "Plugin these assimptions into $w^{(i)}_j$ and finish the E-step:\n",
    "\n",
    "$$w^{(i)}_j=\\frac{\\frac{\\phi_j}{|\\Sigma_j|^{\\frac{1}{2}}}\\exp\\left[-\\frac{1}{2}(x^{(i)}-\\mu_j)^T\\Sigma_j^{-1}(x^{(i)}-\\mu_j)\\right]}{\\sum_{r=1}^k\\frac{\\phi_r}{|\\Sigma_r|\\frac{1}{2}}\\exp\\left[-\\frac{1}{2}(x^{(i)}-\\mu_r)^T\\Sigma_r^{-1}(x^{(i)}-\\mu_r)\\right]}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cdd77a",
   "metadata": {},
   "source": [
    "### (c) Semi-supervised M-step of GMM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0716fb",
   "metadata": {},
   "source": [
    "Some quick facts from [The Matrix Cookbook](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf) used in this problem:\n",
    "\n",
    "1. Quadratic Form to Trace:\n",
    "\\begin{align*}\n",
    "z^TXz=\\text{tr}(Xzz^T).\n",
    "\\end{align*}\n",
    "\n",
    "2. Derivative of Log Determinant:\n",
    "$$\\nabla_{X}log|X|=(X^{-1})^T, |X|>0.$$\n",
    "3. Derivative of Trace with Matrix Inverse:\n",
    "\n",
    "$$\\nabla_{X}\\text{tr}(X^{-1}A)=-(X^{-1}AX^{-1})^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c708101",
   "metadata": {},
   "source": [
    "The objective function is\n",
    "\n",
    "\\begin{align*}\n",
    "l_{\\text{semi-sup}}(\\mu_1,\\Sigma_1,\\phi_1,\\dots,\\mu_k,\\Sigma_k,\\phi_k) &= \\sum_{i=1}^m \\left(\\sum_{j=1}^k w_j^{(i)}\\log\\frac{p(x^{(i)},z^{(i)}=j;\\mu_j,\\Sigma_j,\\phi_j)}{w_j^{(i)}}\\right)\\\\\n",
    "&+\\alpha\\sum_{i=1}^{\\tilde m}\\log p(\\tilde x^{(i)},\\tilde z^{(i)};\\mu_{\\tilde z^{(i)}},\\Sigma_{\\tilde z^{(i)}},\\phi_{\\tilde z^{(i)}})\\\\\n",
    "&=\\sum_{i=1}^m \\sum_{j=1}^kw_{j}^{(i)}\\log\\frac{\\frac{\\phi_j}{(2\\pi)^{\\frac{n}{2}}|\\Sigma_j|^{\\frac{1}{2}}}\\exp\\left[-\\frac{1}{2}(x^{(i)}-\\mu_j)^T\\Sigma_{j}^{-1}(x^{(i)}-\\mu_j)\\right]}{w_{j}^{(i)}}\\\\\n",
    "&+\\alpha\\sum_{i=1}^{\\tilde m}\\log\\frac{\\phi_{\\tilde z^{(i)}}}{(2\\pi)^{\\frac{n}{2}}|\\Sigma_{\\tilde z^{(i)}}|^{\\frac{1}{2}}}\\exp\\left[-\\frac{1}{2}(\\tilde x^{(i)}-\\mu_{\\tilde z^{(i)}})^T\\Sigma_{\\tilde z^{(i)}}^{-1}(\\tilde x^{(i)}-\\mu_{\\tilde z^{(i)}})\\right].\n",
    "\\end{align*}\n",
    "\n",
    "In M-step, we take $w_{j}^{(i)}$'s as constants and compute the derivatives w.r.t. each parameter:\n",
    "\n",
    "\\begin{align*}\n",
    "\n",
    "&\\nabla_{\\mu_r}l_{\\text{semi-sup}}=\\sum_{i=1}^mw_r^{(i)}\\Sigma_r^{-1}(x^{(i)}-\\mu_r)+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}\\Sigma_r^{-1}(\\tilde x^{(i)}-\\mu_r).\n",
    "\n",
    "\\end{align*}\n",
    "\n",
    "To compute $\\nabla_{\\Sigma_r}l_{\\text{semi-sup}}$, first seperate terms related to $\\Sigma_r$:\n",
    "\n",
    "\\begin{align*}\n",
    "L(\\Sigma_r)&=\\sum_{i=1}^mw_r^{(i)}\\left(-\\frac{1}{2}(x^{(i)}-\\mu_r)^T\\Sigma_r^{-1}(x^{(i)}-\\mu_r)-\\frac{1}{2}\\log|\\Sigma_r|\\right)\\\\\n",
    "&+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}\\left(-\\frac{1}{2}\\log|\\Sigma_{r}|-\\frac{1}{2}(\\tilde x^{(i)}-\\mu_{r})^T\\Sigma_{}^{-1}(\\tilde x^{(i)}-\\mu_{r})\\right)\\\\\n",
    "&=-\\frac{1}{2}\\left(\\sum_{i=1}^mw_r^{(i)}+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}\\right)\\log|\\Sigma_r|\\\\\n",
    "&-\\frac{1}{2}\\left(\\sum_{i=1}^mw_r^{(i)}(x^{(i)}-\\mu_r)^T\\Sigma_r^{-1}(x^{(i)}-\\mu_r)+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}(\\tilde x^{(i)}-\\mu_{r})^T\\Sigma_r^{-1}(\\tilde x^{(i)}-\\mu_{r})\\right)\\\\\n",
    "&=-\\frac{1}{2}\\left(\\sum_{i=1}^mw_r^{(i)}+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}\\right)\\log|\\Sigma_r|\\\\\n",
    "&-\\frac{1}{2}\\text{tr}\\left(\\Sigma_r^{-1}\\left(\\sum_{i=1}^mw_r^{(i)}(x^{(i)}-\\mu_r)(x^{(i)}-\\mu_r)^T+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}(\\tilde x^{(i)}-\\mu_{r})(\\tilde x^{(i)}-\\mu_{r})^T\\right)\\right)\n",
    "\\end{align*}\n",
    "\n",
    "Let\n",
    "\n",
    "\\begin{align*}\n",
    "&N_r=\\sum_{i=1}^mw_r^{(i)}+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}\\in\\mathbb R\\\\\n",
    "&S_r=\\sum_{i=1}^mw_r^{(i)}(x^{(i)}-\\mu_r)(x^{(i)}-\\mu_r)^T+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}(\\tilde x^{(i)}-\\mu_{r})(\\tilde x^{(i)}-\\mu_{r})^T\\in\\mathbb R^{n\\times n},\n",
    "\\end{align*}\n",
    "\n",
    "then\n",
    "\n",
    "\\begin{align*}\n",
    "\\nabla_{\\Sigma_r}l_{\\text{semi-sup}}&=\\nabla_{\\Sigma_r}L(\\Sigma_r)\\\\\n",
    "&=-\\frac{1}{2}N_r(\\Sigma_r^{-1})^T+\\frac{1}{2}(\\Sigma_r^{-1}S_r\\Sigma_r^{-1})^T.\n",
    "\\end{align*}\n",
    "\n",
    "Since both $\\Sigma_r$ and $S_r$ are symmetric, \n",
    "\n",
    "\\begin{align*}\n",
    "\\nabla_{\\Sigma_r}l_{\\text{semi-sup}}&=-\\frac{1}{2}N_r\\Sigma_r^{-1}+\\frac{1}{2}\\Sigma_r^{-1}S_r\\Sigma_r^{-1}.\n",
    "\\end{align*}\n",
    "\n",
    "Last, we compute $\\nabla_{\\phi_r}l_{\\text{semi-sup}}$. First, seperate terms related to $\\phi_r$.\n",
    "\\begin{align*}\n",
    "L(\\phi_r)&=\\sum_{i=1}^mw_r^{(i)}\\log\\phi_r+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}\\log\\phi_r\\\\\n",
    "&=\\left(\\sum_{i=1}^mw_r^{(i)}+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}\\right)\\log\\phi_r.\n",
    "\\end{align*}\n",
    "\n",
    "Therefore, \n",
    "\n",
    "\\begin{align*}\n",
    "\\nabla_{\\phi_r}l_{\\text{semi-sup}}&=\\nabla_{\\phi_r}L(\\phi_r)\\\\\n",
    "&=\\frac{1}{\\phi_r}\\left(\\sum_{i=1}^mw_j^{(i)}+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}\\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f9c49b",
   "metadata": {},
   "source": [
    "By setting $\\nabla_{\\mu_r}l_{\\text{semi-sup}}$ and $\\nabla_{\\Sigma_r}l_{\\text{semi-sup}}$ to zero, we can get the MLE of $\\mu_r$ and $\\Sigma_r$, respectively:\n",
    "\n",
    "\\begin{align*}\n",
    "&\\mu_r=\\frac{\\sum_{i=1}^mw_r^{(i)}x^{(i)}+\\alpha\\sum_{i=1}^{\\tilde m}1_{z^{(i)=r}}\\tilde x^{(i)}}{\\sum_{i=1}^m{w_r^{(i)}}+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}}\\\\\n",
    "&\\Sigma_r=\\frac{S_r}{N_r}=\\frac{\\sum_{i=1}^mw_r^{(i)}(x^{(i)}-\\mu_r)(x^{(i)}-\\mu_r)^T+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}(\\tilde x^{(i)}-\\mu_{r})(\\tilde x^{(i)}-\\mu_{r})^T}{\\sum_{i=1}^mw_r^{(i)}+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16641c41",
   "metadata": {},
   "source": [
    "When it comes to $\\phi_r$, note that there is a constraint\n",
    "$$\\sum_{r=1}^k\\phi_r=1.$$\n",
    "\n",
    "Thus, we use Lagrange Multiplier to finish the optimization:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal L(\\phi)&=\\sum_{r=1}^kL(\\phi_r)-\\lambda\\left(\\sum_{r=1}^k\\phi_r-1\\right).\n",
    "\\end{align*}\n",
    "\n",
    "Note we can simply plugin $L(\\phi_r)$ since we operate on the log-likelihood.\n",
    "\n",
    "\\begin{align*}\n",
    "\\nabla_{\\phi_r}\\mathcal L(\\phi)&=\\frac{1}{\\phi_r}\\left(\\sum_{i=1}^mw_r^{(i)}+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}\\right)-\\lambda.\n",
    "\\end{align*}\n",
    "\n",
    "Set the derivative to zero we obtain\n",
    "\n",
    "\\begin{align*}\n",
    "\\phi_r=\\frac{\\sum_{i=1}^mw_r^{(i)}+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}}{\\lambda}\n",
    "\\end{align*}\n",
    "\n",
    "and from the constraint we solve for $\\lambda$:\n",
    "\\begin{align*}\n",
    "\\sum_{r=1}^k \\phi_r&=\\frac{\\sum_{i=1}^m\\sum_{r=1}^kw_r^{(i)}+\\alpha\\sum_{i=1}^{\\tilde m}\\sum_{r=1}^k1_{z^{(i)}=r}}{\\lambda}\\\\\n",
    "&=\\frac{m+\\alpha \\tilde m}{\\lambda}=1\\\\\n",
    "&\\Longrightarrow \\lambda = m+\\alpha \\tilde m.\n",
    "\\end{align*}\n",
    "\n",
    "Therefore, $\\phi_r=\\frac{\\sum_{i=1}^mw_r^{(i)}+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}}{m+\\alpha \\tilde m}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10501286",
   "metadata": {},
   "source": [
    "To summarize,\n",
    "\n",
    "\\begin{align*}\n",
    "&\\mu_r=\\frac{\\sum_{i=1}^mw_r^{(i)}x^{(i)}+\\alpha\\sum_{i=1}^{\\tilde m}1_{z^{(i)=r}}\\tilde x^{(i)}}{\\sum_{i=1}^m{w_r^{(i)}}+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}}\\\\\n",
    "&\\Sigma_r=\\frac{S_r}{N_r}=\\frac{\\sum_{i=1}^mw_r^{(i)}(x^{(i)}-\\mu_r)(x^{(i)}-\\mu_r)^T+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}(\\tilde x^{(i)}-\\mu_{r})(\\tilde x^{(i)}-\\mu_{r})^T}{\\sum_{i=1}^mw_r^{(i)}+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}}\\\\\n",
    "&\\phi_r=\\frac{\\sum_{i=1}^mw_r^{(i)}+\\alpha\\sum_{i=1}^{\\tilde m}1_{\\tilde z^{(i)}=r}}{m+\\alpha \\tilde m},\n",
    "\\end{align*}\n",
    "\n",
    "where $r\\in\\{1,2,\\dots,k\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991bc361",
   "metadata": {},
   "source": [
    "### (d) Classical (Unsupervised) EM Implementation of GMM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bad766",
   "metadata": {},
   "source": [
    "### (e) Semi-supervised EM Implementation of GMM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a35ec9b",
   "metadata": {},
   "source": [
    "### (f) Comparison of Unsupervised and Semi-supervised EM."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
