{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f98bc35a",
   "metadata": {},
   "source": [
    "# PS1-4 Convexity of Generalized Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6216ac",
   "metadata": {},
   "source": [
    "### (a) Relation between expectation and the derivative of $a(\\eta)$ in exponential family."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066d3b26",
   "metadata": {},
   "source": [
    "Notice that $\\int p(y;\\eta)\\mathrm{d}y = 1$. Therefore,\n",
    "\n",
    "\\begin{align*}\n",
    "0&=\\frac{\\partial}{\\partial \\eta} \\int p(y;\\eta)\\mathrm{d}y\\\\\n",
    "&=\\int\\frac{\\partial}{\\partial \\eta} p(y;\\eta)\\mathrm{d}y\\\\\n",
    "&=\\int p(y;\\eta)(y-a'(\\eta)) \\mathrm{d}y\\\\\n",
    "&= \\mathbb{E}(Y|X;\\theta) - a'(\\eta).\n",
    "\\end{align*}\n",
    "\n",
    "Thus, $\\mathbb{E}(Y|X;\\theta) = a'(\\eta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83dcf5d",
   "metadata": {},
   "source": [
    "### (b) Relation between variance and the second derivative of $a(\\eta)$ in exponential family."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab73a86",
   "metadata": {},
   "source": [
    "Similar to (a), leverage second derivative of PDF to obtain the result.\n",
    "\n",
    "\\begin{align*}\n",
    "0&=\\frac{\\partial^2}{\\partial \\eta^2} \\int p(y;\\eta)\\mathrm{d}y\\\\\n",
    "&=\\int p(y;\\eta)\\left[(y-a'(\\eta))^2-a''(\\eta)\\right]\\mathrm{d}y\\\\\n",
    "&= \\mathbb{E}[(Y-a'(\\eta))^2|X;\\theta] - a''(\\eta).\n",
    "\\end{align*}\n",
    "\n",
    "Thus, $\\text{Var}(Y|X;\\theta) = a''(\\eta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1cdb7",
   "metadata": {},
   "source": [
    "### (c) Convexity of the negative log-likelihood (NLL) loss in exponential family."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03438f12",
   "metadata": {},
   "source": [
    "The NLL loss is given by\n",
    "\n",
    "\\begin{align*}\n",
    "l(\\theta)&=-\\sum_{i=1}^m \\left[\\eta y^{(i)}-a(\\eta)\\right] - \\sum_{i=1}^m \\ln b(y^{(i)})\\\\\n",
    "&=-\\sum_{i=1}^m \\left[\\theta^T x^{(i)} y^{(i)} - a(\\theta^T x^{(i)})\\right] - \\sum_{i=1}^m \\ln b(y^{(i)}).\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a190c6",
   "metadata": {},
   "source": [
    "The partial derivative of the NLL loss with respect to $\\theta_j$ is given by\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial l(\\theta)}{\\partial \\theta_j} &= -\\sum_{i=1}^m \\left[x_j^{(i)} y^{(i)} - a'(\\theta^T x^{(i)}) x_j^{(i)}\\right]\\\\\n",
    "&= -\\sum_{i=1}^m \\left[y^{(i)} - a'(\\theta^T x^{(i)})\\right]x_j^{(i)}\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e480643",
   "metadata": {},
   "source": [
    "Let $H$ be Hessian matrix of the NLL loss, then\n",
    "\n",
    "\\begin{align*}\n",
    "H_{jk} &= \\frac{\\partial^2 l(\\theta)}{\\partial \\theta_j \\partial \\theta_k} \\\\\n",
    "&= -\\sum_{i=1}^m -a''(\\theta^T x^{(i)}) x_j^{(i)} x_k^{(i)}\\\\\n",
    "&= \\sum_{i=1}^m a''(\\theta^T x^{(i)}) x_j^{(i)} x_k^{(i)}.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb141b",
   "metadata": {},
   "source": [
    "From (b) we know that $a''(\\theta^Tx^{(i)})$ is the variance of $Y^{(i)}|X^{(i)};\\theta$ and thus non-negative. Therefore, same as 1-1(a), we can conclude that $H$ is PSD, which implies that the NLL loss is convex w.r.t. $\\theta$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ann_snn_ei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
